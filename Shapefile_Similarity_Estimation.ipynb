{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "l0lnU00uId5d",
        "outputId": "768cd214-6e41-4674-9c17-16298fe66aef"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Collecting rasterio\n",
            "  Downloading rasterio-1.4.3-cp311-cp311-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (9.1 kB)\n",
            "Collecting affine (from rasterio)\n",
            "  Downloading affine-2.4.0-py3-none-any.whl.metadata (4.0 kB)\n",
            "Requirement already satisfied: attrs in /usr/local/lib/python3.11/dist-packages (from rasterio) (25.3.0)\n",
            "Requirement already satisfied: certifi in /usr/local/lib/python3.11/dist-packages (from rasterio) (2025.8.3)\n",
            "Requirement already satisfied: click>=4.0 in /usr/local/lib/python3.11/dist-packages (from rasterio) (8.2.1)\n",
            "Collecting cligj>=0.5 (from rasterio)\n",
            "  Downloading cligj-0.7.2-py3-none-any.whl.metadata (5.0 kB)\n",
            "Requirement already satisfied: numpy>=1.24 in /usr/local/lib/python3.11/dist-packages (from rasterio) (2.0.2)\n",
            "Collecting click-plugins (from rasterio)\n",
            "  Downloading click_plugins-1.1.1.2-py2.py3-none-any.whl.metadata (6.5 kB)\n",
            "Requirement already satisfied: pyparsing in /usr/local/lib/python3.11/dist-packages (from rasterio) (3.2.3)\n",
            "Downloading rasterio-1.4.3-cp311-cp311-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (22.2 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m22.2/22.2 MB\u001b[0m \u001b[31m45.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading cligj-0.7.2-py3-none-any.whl (7.1 kB)\n",
            "Downloading affine-2.4.0-py3-none-any.whl (15 kB)\n",
            "Downloading click_plugins-1.1.1.2-py2.py3-none-any.whl (11 kB)\n",
            "Installing collected packages: cligj, click-plugins, affine, rasterio\n",
            "Successfully installed affine-2.4.0 click-plugins-1.1.1.2 cligj-0.7.2 rasterio-1.4.3\n"
          ]
        }
      ],
      "source": [
        "!pip install rasterio"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "metadata": {
        "id": "J_CQFMACp3-i"
      },
      "outputs": [],
      "source": [
        "import geopandas as gpd\n",
        "import rasterio\n",
        "from rasterio.features import geometry_mask\n",
        "from shapely.affinity import rotate\n",
        "import numpy as np\n",
        "import hashlib\n",
        "\n",
        "def shapefile_to_binary_vectors(shapefile_path, raster_resolution):\n",
        "    # Read the shapefile using geopandas\n",
        "    gdf = gpd.read_file(shapefile_path)\n",
        "\n",
        "    all_shape_arrays = []\n",
        "\n",
        "    for index, row in gdf.iterrows():\n",
        "        # Get the geometry of the current feature\n",
        "        geometry = row['geometry']\n",
        "\n",
        "        # Get the bounding box of the shapefile\n",
        "        bounding_box = geometry.bounds\n",
        "\n",
        "        # Calculate the aspect ratio of the original shapefile\n",
        "        if (bounding_box[3] - bounding_box[1]) > (bounding_box[2] - bounding_box[0]):\n",
        "          aspect_ratio = (bounding_box[2] - bounding_box[0]) / (bounding_box[3] - bounding_box[1])\n",
        "          tall = True\n",
        "        else:\n",
        "          aspect_ratio = (bounding_box[3] - bounding_box[1]) / (bounding_box[2] - bounding_box[0])\n",
        "          tall = False\n",
        "        # tall indicates whether the shape is taller than it is wide or not\n",
        "\n",
        "        # Adjust placement of shape based on the aspect ratio\n",
        "        if tall:\n",
        "          raster_resolutions = (\n",
        "              int(raster_resolution * aspect_ratio),\n",
        "              raster_resolution\n",
        "          )\n",
        "        else:\n",
        "          raster_resolutions = (\n",
        "              raster_resolution,\n",
        "              int(raster_resolution * aspect_ratio)\n",
        "          )\n",
        "\n",
        "        # Create a raster from the shapefile\n",
        "        with rasterio.Env():\n",
        "            with rasterio.open(\n",
        "                'output_raster.tif',\n",
        "                'w',\n",
        "                driver='GTiff',\n",
        "                height=raster_resolutions[1],\n",
        "                width=raster_resolutions[0],\n",
        "                count=1,\n",
        "                dtype=np.uint8,\n",
        "                crs='EPSG:4326', # Mercator projection\n",
        "                transform=rasterio.transform.from_bounds(*bounding_box, *raster_resolutions),\n",
        "            ) as dst:\n",
        "                # Rasterize the shapefile\n",
        "                mask = geometry_mask(\n",
        "                    [geometry],\n",
        "                    out_shape=(raster_resolutions[1], raster_resolutions[0]),\n",
        "                    transform=dst.transform,\n",
        "                    invert=True\n",
        "                )\n",
        "                dst.write(mask.astype(np.uint8), 1)\n",
        "\n",
        "        # Read the raster and convert it to a binary array\n",
        "        with rasterio.open('output_raster.tif') as src:\n",
        "            raster_array = src.read(1)\n",
        "            binary_array = (raster_array > 0).astype(np.uint8)\n",
        "\n",
        "        shape_array = []\n",
        "\n",
        "        # Converts array of arrays into a single vector\n",
        "        if tall:\n",
        "          for i in range(raster_resolution):\n",
        "            for j in range(len(binary_array[0])):\n",
        "              shape_array.append(binary_array[i][j])\n",
        "            for j in range(raster_resolution - len(binary_array[0])):\n",
        "              shape_array.append(0)\n",
        "        else:\n",
        "          for i in range(len(binary_array)):\n",
        "            for j in range(raster_resolution):\n",
        "              shape_array.append(binary_array[i][j])\n",
        "          for j in range(raster_resolution - len(binary_array)):\n",
        "            for j in range(raster_resolution):\n",
        "              shape_array.append(0)\n",
        "\n",
        "        # Add to list of vectors\n",
        "        all_shape_arrays.append(shape_array)\n",
        "\n",
        "    return all_shape_arrays\n",
        "\n",
        "raster_resolution = 100\n",
        "shapefile_path2 = 'world_countries.shp'\n",
        "\n",
        "feature_names = gpd.read_file(shapefile_path2)['CNTRY_NAME'] # Getting names attribute from shapefile\n",
        "\n",
        "dataset = shapefile_to_binary_vectors(shapefile_path2, raster_resolution)"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "def minhash_vector(vector, seed):\n",
        "    # Seed so randomness is always the same\n",
        "    np.random.seed(seed)\n",
        "\n",
        "    # Get \"hash function\" from indices to interval [0,1]\n",
        "    random_vector = np.random.uniform(0,1,size=len(vector))\n",
        "\n",
        "    # Start minimum value at 1\n",
        "    minhash = 1\n",
        "\n",
        "    # Iterate over the elements of the binary vector.\n",
        "    for i in range(len(vector)):\n",
        "      if vector[i] == 1:\n",
        "        # Calculate the hash value of the element.\n",
        "        hash_value = random_vector[i]\n",
        "\n",
        "        # Update the minhash if the hash value is smaller.\n",
        "        minhash = min(minhash, hash_value)\n",
        "\n",
        "    # Return the minhash.\n",
        "    return minhash\n",
        "\n",
        "def create_tuple_dataset(dataset, r):\n",
        "\n",
        "    # Create output arrays\n",
        "    dataset_tuple = np.zeros((len(dataset),r))\n",
        "\n",
        "    for i in range(r):\n",
        "      # Generate random seed for hash function\n",
        "      seed = r_seeds[i]\n",
        "\n",
        "      # Minhases for each vector in the dataset\n",
        "      for j in range(len(dataset)):\n",
        "        dataset_tuple[j][i] = minhash_vector(dataset[j], seed)\n",
        "\n",
        "    return dataset_tuple\n",
        "\n",
        "def hash_tuple(tuple_object, m, seed):\n",
        "    # Convert the tuple object to a string.\n",
        "    tuple_string = str(tuple_object)\n",
        "\n",
        "    # Create a hash object with the specified seed.\n",
        "    hash_object = hashlib.sha256(str(seed).encode('utf-8'))\n",
        "\n",
        "    # Update the hash object with the tuple string.\n",
        "    hash_object.update(tuple_string.encode('utf-8'))\n",
        "\n",
        "    # Get the hash value as a hexadecimal string.\n",
        "    hash_value = hash_object.hexdigest()\n",
        "\n",
        "    # Convert the hexadecimal string to an integer.\n",
        "    hash_value_int = int(hash_value, 16)\n",
        "\n",
        "    # Return the hash value modulo m.\n",
        "    return hash_value_int % m + 1\n",
        "\n",
        "def create_table_dataset(dataset_tuple, t, m):\n",
        "    # Create output tables\n",
        "    dataset_table = np.zeros((len(dataset_tuple),t))\n",
        "\n",
        "    for i in range(t):\n",
        "      # Generate random seed for hash function\n",
        "      seed = t_seeds[i]\n",
        "\n",
        "      # Hashes indexes for each vector in the dataset\n",
        "      for j in range(len(dataset_tuple)):\n",
        "        dataset_table[j][i] = hash_tuple(dataset_tuple[j], m, seed)\n",
        "\n",
        "    return dataset_table\n",
        "\n",
        "r = 11 # Number of times our minhash funtion will be ran\n",
        "m = 2 * len(feature_names) # Number of possible indexes to hash to in table\n",
        "t = 250 # Number of rows in the table\n",
        "\n",
        "r_seeds = []\n",
        "t_seeds = []\n",
        "\n",
        "# Generate random seeds for hash functions\n",
        "for i in range(r):\n",
        "    r_seeds.append(np.random.randint(0,1000000))\n",
        "\n",
        "for i in range(t):\n",
        "    t_seeds.append(np.random.randint(0,1000000))\n",
        "\n",
        "# Create tuples for the vector and dataset\n",
        "dataset_tuple = create_tuple_dataset(dataset, r)\n",
        "\n",
        "# Create tables for the vector and dataset\n",
        "dataset_table = create_table_dataset(dataset_tuple, t, m)"
      ],
      "metadata": {
        "id": "sUMaa4CD1rUA"
      },
      "execution_count": 45,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": 46,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "D_Y3EPtAiW_4",
        "outputId": "1cc12cbc-8801-4b5a-c765-b785e0b09999"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Checking 92 countries for your shape rotated at 0 degrees.\n",
            "Checking 93 countries for your shape rotated at 5 degrees.\n",
            "Checking 105 countries for your shape rotated at 10 degrees.\n",
            "Checking 99 countries for your shape rotated at 15 degrees.\n",
            "Checking 104 countries for your shape rotated at 20 degrees.\n",
            "Checking 86 countries for your shape rotated at 25 degrees.\n",
            "Checking 86 countries for your shape rotated at 30 degrees.\n",
            "Checking 87 countries for your shape rotated at 35 degrees.\n",
            "Checking 102 countries for your shape rotated at 40 degrees.\n",
            "Checking 84 countries for your shape rotated at 45 degrees.\n",
            "Checking 110 countries for your shape rotated at 50 degrees.\n",
            "Checking 88 countries for your shape rotated at 55 degrees.\n",
            "Checking 105 countries for your shape rotated at 60 degrees.\n",
            "Checking 110 countries for your shape rotated at 65 degrees.\n",
            "Checking 88 countries for your shape rotated at 70 degrees.\n",
            "Checking 102 countries for your shape rotated at 75 degrees.\n",
            "Checking 89 countries for your shape rotated at 80 degrees.\n",
            "Checking 95 countries for your shape rotated at 85 degrees.\n",
            "Checking 84 countries for your shape rotated at 90 degrees.\n",
            "Checking 110 countries for your shape rotated at 95 degrees.\n",
            "Checking 88 countries for your shape rotated at 100 degrees.\n",
            "Checking 84 countries for your shape rotated at 105 degrees.\n",
            "Checking 106 countries for your shape rotated at 110 degrees.\n",
            "Checking 86 countries for your shape rotated at 115 degrees.\n",
            "Checking 123 countries for your shape rotated at 120 degrees.\n",
            "Checking 123 countries for your shape rotated at 125 degrees.\n",
            "Checking 116 countries for your shape rotated at 130 degrees.\n",
            "Checking 116 countries for your shape rotated at 135 degrees.\n",
            "Checking 97 countries for your shape rotated at 140 degrees.\n",
            "Checking 81 countries for your shape rotated at 145 degrees.\n",
            "Checking 80 countries for your shape rotated at 150 degrees.\n",
            "Checking 88 countries for your shape rotated at 155 degrees.\n",
            "Checking 96 countries for your shape rotated at 160 degrees.\n",
            "Checking 105 countries for your shape rotated at 165 degrees.\n",
            "Checking 83 countries for your shape rotated at 170 degrees.\n",
            "Checking 91 countries for your shape rotated at 175 degrees.\n",
            "Checking 86 countries for your shape rotated at 180 degrees.\n",
            "Checking 84 countries for your shape rotated at 185 degrees.\n",
            "Checking 84 countries for your shape rotated at 190 degrees.\n",
            "Checking 102 countries for your shape rotated at 195 degrees.\n",
            "Checking 104 countries for your shape rotated at 200 degrees.\n",
            "Checking 103 countries for your shape rotated at 205 degrees.\n",
            "Checking 108 countries for your shape rotated at 210 degrees.\n",
            "Checking 96 countries for your shape rotated at 215 degrees.\n",
            "Checking 96 countries for your shape rotated at 220 degrees.\n",
            "Checking 88 countries for your shape rotated at 225 degrees.\n",
            "Checking 87 countries for your shape rotated at 230 degrees.\n",
            "Checking 110 countries for your shape rotated at 235 degrees.\n",
            "Checking 83 countries for your shape rotated at 240 degrees.\n",
            "Checking 92 countries for your shape rotated at 245 degrees.\n",
            "Checking 79 countries for your shape rotated at 250 degrees.\n",
            "Checking 87 countries for your shape rotated at 255 degrees.\n",
            "Checking 88 countries for your shape rotated at 260 degrees.\n",
            "Checking 89 countries for your shape rotated at 265 degrees.\n",
            "Checking 95 countries for your shape rotated at 270 degrees.\n",
            "Checking 108 countries for your shape rotated at 275 degrees.\n",
            "Checking 112 countries for your shape rotated at 280 degrees.\n",
            "Checking 97 countries for your shape rotated at 285 degrees.\n",
            "Checking 104 countries for your shape rotated at 290 degrees.\n",
            "Checking 104 countries for your shape rotated at 295 degrees.\n",
            "Checking 98 countries for your shape rotated at 300 degrees.\n",
            "Checking 92 countries for your shape rotated at 305 degrees.\n",
            "Checking 92 countries for your shape rotated at 310 degrees.\n",
            "Checking 94 countries for your shape rotated at 315 degrees.\n",
            "Checking 109 countries for your shape rotated at 320 degrees.\n",
            "Checking 98 countries for your shape rotated at 325 degrees.\n",
            "Checking 110 countries for your shape rotated at 330 degrees.\n",
            "Checking 107 countries for your shape rotated at 335 degrees.\n",
            "Checking 98 countries for your shape rotated at 340 degrees.\n",
            "Checking 112 countries for your shape rotated at 345 degrees.\n",
            "Checking 101 countries for your shape rotated at 350 degrees.\n",
            "Checking 99 countries for your shape rotated at 355 degrees.\n",
            "The country most similar to your shape is Peru with a similarity score of 0.7551194539249146 rotated at 40 degrees.\n"
          ]
        }
      ],
      "source": [
        "def shapefile_to_binary_vector_rotate(shapefile_path, raster_resolution, rotation_angle):\n",
        "    # Read the shapefile\n",
        "    gdf = gpd.read_file(shapefile_path)\n",
        "\n",
        "    # Convert shapefile to polygon through unifying features\n",
        "    polygon = gdf.union_all()\n",
        "\n",
        "    # Rotate the polygon\n",
        "    rotated_polygon = rotate(polygon, rotation_angle)\n",
        "\n",
        "    # Create a bounds for the rotated polygon\n",
        "    bounding_box = rotated_polygon.bounds\n",
        "\n",
        "    # Calculate the aspect ratio of the original shapefile\n",
        "    if (bounding_box[3] - bounding_box[1]) > (bounding_box[2] - bounding_box[0]):\n",
        "      aspect_ratio = (bounding_box[2] - bounding_box[0]) / (bounding_box[3] - bounding_box[1])\n",
        "      tall = True\n",
        "    else:\n",
        "      aspect_ratio = (bounding_box[3] - bounding_box[1]) / (bounding_box[2] - bounding_box[0])\n",
        "      tall = False\n",
        "    # tall indicates whether the shape is taller than it is wide or not\n",
        "\n",
        "    # Adjust placement of shape based on the aspect ratio\n",
        "    if tall:\n",
        "      raster_resolutions = (\n",
        "          int(raster_resolution * aspect_ratio),\n",
        "          raster_resolution\n",
        "      )\n",
        "    else:\n",
        "      raster_resolutions = (\n",
        "          raster_resolution,\n",
        "          int(raster_resolution * aspect_ratio)\n",
        "      )\n",
        "\n",
        "    # Create a raster from the rotated polygon\n",
        "    with rasterio.Env():\n",
        "        with rasterio.open(\n",
        "            'output_raster.tif',\n",
        "            'w',\n",
        "            driver='GTiff',\n",
        "            height=raster_resolutions[1],\n",
        "            width=raster_resolutions[0],\n",
        "            count=1,\n",
        "            dtype=np.uint8,\n",
        "            crs=\"EPSG:4326\", # Mercator projection\n",
        "            transform=rasterio.transform.from_bounds(*bounding_box, *raster_resolutions),\n",
        "        ) as dst:\n",
        "            mask = geometry_mask(\n",
        "                [rotated_polygon],\n",
        "                out_shape=(raster_resolutions[1], raster_resolutions[0]),\n",
        "                transform=dst.transform,\n",
        "                invert=True\n",
        "            )\n",
        "            dst.write(mask.astype(np.uint8), 1)\n",
        "\n",
        "    # Read the raster and convert it to a binary array\n",
        "    with rasterio.open('output_raster.tif') as src:\n",
        "        raster_array = src.read(1)\n",
        "        binary_array = (raster_array > 0).astype(np.uint8)\n",
        "\n",
        "    shape_array = []\n",
        "\n",
        "    # Converts array of arrays into a single vector\n",
        "    if tall:\n",
        "      for i in range(raster_resolution):\n",
        "        for j in range(len(binary_array[0])):\n",
        "          shape_array.append(binary_array[i][j])\n",
        "        for j in range(raster_resolution - len(binary_array[0])):\n",
        "          shape_array.append(0)\n",
        "    else:\n",
        "      for i in range(len(binary_array)):\n",
        "        for j in range(raster_resolution):\n",
        "          shape_array.append(binary_array[i][j])\n",
        "      for j in range(raster_resolution - len(binary_array)):\n",
        "        for j in range(raster_resolution):\n",
        "          shape_array.append(0)\n",
        "\n",
        "    return shape_array\n",
        "\n",
        "def create_tuple_vector(vector, r):\n",
        "\n",
        "    # Create output arrays\n",
        "    vector_tuple = np.zeros(r)\n",
        "\n",
        "    for i in range(r):\n",
        "      # Generate random seed for hash function\n",
        "      seed = r_seeds[i]\n",
        "\n",
        "      # Minhashes for sample vector\n",
        "      vector_tuple[i] = minhash_vector(vector, seed)\n",
        "\n",
        "    return vector_tuple\n",
        "\n",
        "def create_table_vector(vector_tuple, t, m):\n",
        "    # Create output tables\n",
        "    vector_table = np.zeros(t)\n",
        "\n",
        "    for i in range(t):\n",
        "      # Generate random seed for hash function\n",
        "      seed = t_seeds[i]\n",
        "\n",
        "      # Hashes indexes for sample vector\n",
        "      vector_table[i] = hash_tuple(vector_tuple, m, seed)\n",
        "\n",
        "    return vector_table\n",
        "\n",
        "def check_table(vector_table, dataset_table):\n",
        "    # Create list for indexes to be appended on to\n",
        "    check_list = []\n",
        "\n",
        "    # Iterates through table to find matches in the sample vector to the dataset\n",
        "    for i in range(len(vector_table)):\n",
        "      for j in range(len(dataset_table)):\n",
        "        if vector_table[i] == dataset_table[j][i]:\n",
        "          check_list.append(j)\n",
        "\n",
        "    return list(set(check_list))\n",
        "\n",
        "def jaccards(vector1, vector2):\n",
        "    intersection = 0\n",
        "    union = 0\n",
        "\n",
        "    # For each 1 or 0 in the vectors, the intersection or union value will increase\n",
        "    for i in range(len(vector1)):\n",
        "      if vector1[i] == 1 and vector2[i] == 1:\n",
        "        intersection += 1\n",
        "      if vector1[i] == 1 or vector2[i] == 1:\n",
        "        union += 1\n",
        "\n",
        "    # Returns similairty value from 0 to 1. 1 is most similar.\n",
        "    return intersection / union\n",
        "\n",
        "def max_similarity(vector, dataset, check_list):\n",
        "    # Set initial values for the maximum similarity and the maximum index at that similarity\n",
        "    max_similarity = 0\n",
        "    max_index = 0\n",
        "\n",
        "    # Find similarity for each index in the check list, store only maximum\n",
        "    for i in range(len(check_list)):\n",
        "      sim = jaccards(vector, dataset[check_list[i]])\n",
        "      if max_similarity < sim:\n",
        "        max_similarity = sim\n",
        "        max_index = check_list[i]\n",
        "\n",
        "    return max_similarity, max_index\n",
        "\n",
        "# Example usage\n",
        "shapefile_path1 = 'VT_counties.shp'\n",
        "\n",
        "total_max_sim = 0\n",
        "\n",
        "total_max_index = 0\n",
        "\n",
        "max_degree = 0\n",
        "\n",
        "# Repeat for multiple rotations\n",
        "for i in range(72):\n",
        "  # get a binary vector from shapefile\n",
        "  vector = shapefile_to_binary_vector_rotate(shapefile_path1, raster_resolution, i * 5)\n",
        "\n",
        "  # Create tuples for the vector and dataset\n",
        "  vector_tuple = create_tuple_vector(vector, r)\n",
        "\n",
        "  # Create tables for the vector and dataset\n",
        "  vector_table = create_table_vector(vector_tuple, t, m)\n",
        "\n",
        "  # Generate a list of which shapes in the dataset to check\n",
        "  check_list = check_table(vector_table, dataset_table)\n",
        "\n",
        "  print(\"Checking\",len(check_list),\"countries for your shape rotated at\", i * 5, \"degrees.\")\n",
        "\n",
        "  # Find maximum similarity for all checks\n",
        "  max_sim, max_index = max_similarity(vector, dataset, check_list)\n",
        "  if max_sim > total_max_sim:\n",
        "    total_max_sim = max_sim\n",
        "    total_max_index = max_index\n",
        "    max_degree = i * 5\n",
        "\n",
        "max_country = feature_names[total_max_index]\n",
        "\n",
        "print('The country most similar to your shape is',max_country,'with a similarity score of',total_max_sim, 'rotated at', max_degree, 'degrees.')"
      ]
    }
  ],
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}